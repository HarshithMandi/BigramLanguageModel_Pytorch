{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ba9c37c-bc1a-4e25-bfe3-050614c1a1dd",
   "metadata": {},
   "source": [
    "# Bigram Language Model\n",
    "### inspired by Andrej Karpathy's tutorial & the paper \"Attention Is All You Need\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fadd31e8-c4d3-48a1-b0a8-0c26dd987f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9942b748-d61a-4ef1-af75-3c219d16e762",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "#operations related to matrices\n",
    "zeroes=torch.zeros(1,1)\n",
    "end_time=time.time()\n",
    "end_time-start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "549d6cc2-9b2c-4bff-8c70-aad0928e5c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('wiz_of_oz.txt','r',encoding='utf-8') as f:\n",
    "    text=f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b690b89f-8815-478e-96a1-8fe0f59c0f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"&'(),-.0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWYZabcdefghijklmnopqrstuvwxyzï»¿\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars=sorted(list(set(text)))\n",
    "vocab_size=len(chars)\n",
    "print(''.join(chars))\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "646bf8d9-38bb-4b8c-8c47-081db0913a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_embed=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9df75ff8-9154-4bce-8810-ae91115cc759",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "str_to_int={ch:i for i,ch in enumerate(chars)}\n",
    "int_to_str={i:ch for i,ch in enumerate(chars)}\n",
    "encode= lambda s: [str_to_int[c] for c in s]\n",
    "decode= lambda l: ''.join([int_to_str[i]for i in l])\n",
    "\n",
    "print(decode(encode('hello')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "35704ca3-cc24-4e76-a4c0-9a27711a9797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([75, 39, 66,  ..., 69, 61, 10])\n"
     ]
    }
   ],
   "source": [
    "data=torch.tensor(encode(text),dtype=torch.long)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4fdab06e-e334-46f3-820b-f829f7b4b91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n= int(0.9* len(data))\n",
    "train_data= data[:n]\n",
    "val_data=data[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "16b63998-df67-4ddf-a3bd-8fef119fe1d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([75, 39, 66, 63, 52, 69, 51, 53, 52])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size=8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "25312b94-6761-4c77-91cb-e5c52e04fdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when i/p is tensor([75]) the target is 39\n",
      "when i/p is tensor([75, 39]) the target is 66\n",
      "when i/p is tensor([75, 39, 66]) the target is 63\n",
      "when i/p is tensor([75, 39, 66, 63]) the target is 52\n",
      "when i/p is tensor([75, 39, 66, 63, 52]) the target is 69\n",
      "when i/p is tensor([75, 39, 66, 63, 52, 69]) the target is 51\n",
      "when i/p is tensor([75, 39, 66, 63, 52, 69, 51]) the target is 53\n",
      "when i/p is tensor([75, 39, 66, 63, 52, 69, 51, 53]) the target is 52\n"
     ]
    }
   ],
   "source": [
    "x=train_data[:block_size]\n",
    "y=train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context=x[:t+1]\n",
    "    target=y[t]\n",
    "    print(f'when i/p is {context} the target is {target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2f3b11ff-8a7e-4ea6-93b4-ddf343b4834d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[52,  1, 56, 57, 67,  1, 56, 53],\n",
      "        [ 1, 51, 49, 62,  5, 68,  1, 59],\n",
      "        [51, 63, 70, 53, 66, 53, 52,  1],\n",
      "        [56, 53, 66, 53,  1, 57, 67,  1]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 1, 56, 57, 67,  1, 56, 53, 49],\n",
      "        [51, 49, 62,  5, 68,  1, 59, 53],\n",
      "        [63, 70, 53, 66, 53, 52,  1, 56],\n",
      "        [53, 66, 53,  1, 57, 67,  1, 49]])\n",
      "when input is[52] the target: 1\n",
      "when input is[52, 1] the target: 56\n",
      "when input is[52, 1, 56] the target: 57\n",
      "when input is[52, 1, 56, 57] the target: 67\n",
      "when input is[52, 1, 56, 57, 67] the target: 1\n",
      "when input is[52, 1, 56, 57, 67, 1] the target: 56\n",
      "when input is[52, 1, 56, 57, 67, 1, 56] the target: 53\n",
      "when input is[52, 1, 56, 57, 67, 1, 56, 53] the target: 49\n",
      "when input is[1] the target: 51\n",
      "when input is[1, 51] the target: 49\n",
      "when input is[1, 51, 49] the target: 62\n",
      "when input is[1, 51, 49, 62] the target: 5\n",
      "when input is[1, 51, 49, 62, 5] the target: 68\n",
      "when input is[1, 51, 49, 62, 5, 68] the target: 1\n",
      "when input is[1, 51, 49, 62, 5, 68, 1] the target: 59\n",
      "when input is[1, 51, 49, 62, 5, 68, 1, 59] the target: 53\n",
      "when input is[51] the target: 63\n",
      "when input is[51, 63] the target: 70\n",
      "when input is[51, 63, 70] the target: 53\n",
      "when input is[51, 63, 70, 53] the target: 66\n",
      "when input is[51, 63, 70, 53, 66] the target: 53\n",
      "when input is[51, 63, 70, 53, 66, 53] the target: 52\n",
      "when input is[51, 63, 70, 53, 66, 53, 52] the target: 1\n",
      "when input is[51, 63, 70, 53, 66, 53, 52, 1] the target: 56\n",
      "when input is[56] the target: 53\n",
      "when input is[56, 53] the target: 66\n",
      "when input is[56, 53, 66] the target: 53\n",
      "when input is[56, 53, 66, 53] the target: 1\n",
      "when input is[56, 53, 66, 53, 1] the target: 57\n",
      "when input is[56, 53, 66, 53, 1, 57] the target: 67\n",
      "when input is[56, 53, 66, 53, 1, 57, 67] the target: 1\n",
      "when input is[56, 53, 66, 53, 1, 57, 67, 1] the target: 49\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size=4 #for parallel processing by gpu\n",
    "block_size=8 # maximum context length\n",
    "def get_batch(split):\n",
    "    #generate small batch of data of inputs x and targets y\n",
    "    data= train_data if split == 'train' else val_data\n",
    "    ix=torch.randint(len(data)-block_size,(batch_size,))\n",
    "    x= torch.stack([data[i:i+block_size]for i in ix])\n",
    "    y=torch.stack([data[i+1:i+block_size+1]for i in ix])\n",
    "    return x,y\n",
    "\n",
    "\n",
    "xb,yb= get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "for b in range(batch_size):# batch dimension\n",
    "    for t in range(block_size):# time aspect\n",
    "        context= xb[b, :t+1]\n",
    "        target = yb[b,t]\n",
    "        print(f'when input is{context.tolist()} the target: {target}')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3d14e343-3cf2-4fb0-9943-91d030cbd4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[52,  1, 56, 57, 67,  1, 56, 53],\n",
      "        [ 1, 51, 49, 62,  5, 68,  1, 59],\n",
      "        [51, 63, 70, 53, 66, 53, 52,  1],\n",
      "        [56, 53, 66, 53,  1, 57, 67,  1]])\n"
     ]
    }
   ],
   "source": [
    "print(xb)#i/p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "7d694c46-7516-4867-968f-9b555b6bcf00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape: torch.Size([32, 100])\n",
      "Loss: 5.012180805206299\n",
      "Generated sequence: tensor([[ 0, 67,  9, 75, 73, 62, 66, 16, 49, 30,  7, 90, 26, 61, 41, 53, 61, 78,\n",
      "          6, 38, 67, 68, 27, 24, 66, 90,  6, 62, 20, 58, 23,  0, 48, 10, 94, 19,\n",
      "         69, 73, 88, 90, 14, 18, 55, 13, 92, 87, 10, 36, 76, 31, 60, 45, 27,  7,\n",
      "          9, 72, 31, 25,  5, 90, 12, 92, 24,  9, 39, 33, 46, 57, 40, 37, 88, 69,\n",
      "         77, 58, 54, 80, 26, 26, 96, 68, 55, 41, 14,  6,  4, 60,  8, 58, 71, 72,\n",
      "         56,  1, 42, 36,  9,  2, 16, 20, 39, 66, 43]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        # Each token reads off the logits for the next token from the lookup table\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "        self.position_embedding_table = nn.Embedding(100, vocab_size)\n",
    "        self.lm_head = nn.Linear(vocab_size, vocab_size)\n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        idx = idx.to(device).long()\n",
    "        tok_emb = self.token_embedding_table(idx)  # (Batch, Time, Channel)\n",
    "        B, T, C = tok_emb.shape\n",
    "        pos_emb = self.position_embedding_table(torch.arange(T, device=idx.device))  # (Time, Channel)\n",
    "        x = tok_emb + pos_emb  # (B, T, C)\n",
    "        logits = self.lm_head(x)  # (Batch, Time, Vocab_size)\n",
    "        \n",
    "        if targets is not None:\n",
    "            targets = targets.to(device).view(B * T)\n",
    "            logits = logits.view(B * T, C)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            return logits, loss\n",
    "        \n",
    "        return logits\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        idx = idx.to(device).long()\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits = self(idx)  # (B, T, C)\n",
    "            logits = logits[:, -1, :]  # (B, C)\n",
    "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)  # Append to the sequence\n",
    "        return idx\n",
    "\n",
    "# Sample input data\n",
    "#vocab_size = 100\n",
    "#B, T = 4, 8\n",
    "#xb = torch.randint(0, vocab_size, (B, T)).to(device)\n",
    "#yb = torch.randint(0, vocab_size, (B, T)).to(device)\n",
    "\n",
    "# Initialize the model\n",
    "m = BigramLanguageModel(vocab_size).to(device)\n",
    "\n",
    "# Forward pass\n",
    "logits, loss = m(xb, yb)\n",
    "print(f\"Logits shape: {logits.shape}\")  # Should print: torch.Size([32, 100])\n",
    "print(f\"Loss: {loss}\")  # Should print the loss value\n",
    "\n",
    "# Generate new tokens\n",
    "idx = torch.zeros(1, 1, dtype=torch.long).to(device)\n",
    "generated = m.generate(idx, max_new_tokens=100)\n",
    "print(f\"Generated sequence: {generated}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bdf26a3e-90d1-49e0-a622-6c06e69b7a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model\n",
    "#pytorch optimizer\n",
    "optimizer= torch. optim.AdamW(m.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0ebd71ac-119a-4547-8a05-4ba2b2442b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4316916465759277\n"
     ]
    }
   ],
   "source": [
    "batch_size=32\n",
    "for steps in range (100000):\n",
    "    # sample a batch of data\n",
    "    xb,yb = get_batch('train')\n",
    "\n",
    "    # eval of loss\n",
    "    logits, loss= m(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e5b1a3f7-9246-48df-908c-1e9a314289cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "for personal reference:\n",
      "\n",
      "pthent thored, onoorex uld ens t. s\n",
      "the ttyeere ndrod an cees, l bimepe be ce adother anten thowad ofo o a he aree rs aithy\n",
      "\" ispe tereno\n",
      "\n",
      "\n",
      "oue s m.\n",
      "\n",
      "\"I'mbarea prno sly or licley jonid end y, hespoct He rd id-ho drothelamerke blthe pat ings\n",
      "\n",
      "\n",
      "warairerdornt ppilvan Fiss. tinser epleas.\n",
      "\" k rde oved tiza evererithar be u je-Buapeace\n",
      "\n",
      "usand spempsisemplled hethe arimare be t,\"Wimeeahonesthan's pls ld\n"
     ]
    }
   ],
   "source": [
    "#for personal reference to check performance\n",
    "print(\"\\nfor personal reference:\")\n",
    "#creating a 1X1 tensor and generating 400 tokens\n",
    "print(decode(m.generate(idx=torch.zeros((1,1), dtype=torch.long), max_new_tokens=400)[0].tolist()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee904c0e-5e22-491e-95e9-9c261903f21d",
   "metadata": {},
   "source": [
    "## Math trick for self-attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f4218227-464f-49f3-976f-6c5fea93ca36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 2])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set up a means for tokens to communicate\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "B,T,C = 4,8,2 # batch time and channels\n",
    "x = torch.randn(B,T,C)\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d3cb04ee-6da5-40e9-832e-a8afd2f30e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get x[b,t] = avg(mean {i<=t} x[b,i])\n",
    "\n",
    "xbow = torch.zeros((B,T,C))     #bag of words|| avg\n",
    "for b in range(B):\n",
    "    for t in range(T):\n",
    "        xprev= x[b,:t+1] #(t,C)\n",
    "        xbow[b,t]= torch.mean(xprev,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "efba4be9-b661-433d-827b-c47d8a92e514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "--\n",
      "b:\n",
      "tensor([[5., 7.],\n",
      "        [2., 0.],\n",
      "        [5., 3.]])\n",
      "--\n",
      "c:\n",
      "tensor([[5.0000, 7.0000],\n",
      "        [3.5000, 3.5000],\n",
      "        [4.0000, 3.3333]])\n",
      "--\n"
     ]
    }
   ],
   "source": [
    "#using matrix multiplication\n",
    "torch.manual_seed(1337)\n",
    "a= torch.tril(torch.ones(3,3))\n",
    "a= a/ torch.sum(a,1,keepdim=True)\n",
    "b=torch.randint(0,10,(3,2)).float()\n",
    "c=a@b\n",
    "print(f\"a:\\n{a}\\n--\")\n",
    "print(f\"b:\\n{b}\\n--\")\n",
    "print(f\"c:\\n{c}\\n--\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c60107a4-f72e-495a-8349-b196e47609ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#version 2:\n",
    "\n",
    "wei= torch.tril(torch.ones(T,T))\n",
    "wei = wei/ wei.sum(1, keepdim=True)\n",
    "xbow2= wei @ x # (T,T) @ (B,T,C)---->(b,t,c)\n",
    "#------>torch.allclose(xbow,xbow2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3aeb6cfa-2f87-4a3a-9f2b-4908e3100372",
   "metadata": {},
   "outputs": [],
   "source": [
    "#version 3: use softmax\n",
    "\n",
    "tril=torch.tril(torch.ones(T,T))\n",
    "wei= torch.zeros((T,T))\n",
    "wei= wei.masked_fill(tril==0, float('inf'))\n",
    "wei=F.softmax(wei,dim=-1)\n",
    "xbow3=wei@x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "373951ab-54e4-4ee5-aa21-3bd81ef98ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 8, 16])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 4: self-attention\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "B,T,C=4,8,32 # batch, time and channels\n",
    "x=torch.randn(B,T,C)\n",
    "\n",
    "#a single head's performance in self attention\n",
    "head_size=16\n",
    "key= nn.Linear(C,head_size, bias=False)\n",
    "query= nn.Linear(C,head_size, bias=False)\n",
    "value= nn.Linear(C,head_size, bias=False)\n",
    "k=key(x) #(B,T,16)\n",
    "q=query(x) #(B,T,16)\n",
    "\n",
    "wei= q@ k.transpose(-2,-1) #-->(B,T,16) @ (B,16,T)-->(B,T,T))\n",
    "\n",
    "\n",
    "tril=torch.tril(torch.ones(T,T))\n",
    "#wei=torch.zeros((T,T))\n",
    "wei=wei.masked_fill(tril==0, float('-inf'))\n",
    "wei=F.softmax(wei,dim=-1)\n",
    "v=value(x)\n",
    "out=wei@v\n",
    "#out= wei@ x\n",
    "out. shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "bcd30c1b-791c-4df4-a8b3-4839a3ad1706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tril"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4c852402-e5f8-476d-b36d-a0a811d4b740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1574, 0.8426, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2088, 0.1646, 0.6266, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.5792, 0.1187, 0.1889, 0.1131, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0294, 0.1052, 0.0469, 0.0276, 0.7909, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0176, 0.2689, 0.0215, 0.0089, 0.6812, 0.0019, 0.0000, 0.0000],\n",
       "         [0.1691, 0.4066, 0.0438, 0.0416, 0.1048, 0.2012, 0.0329, 0.0000],\n",
       "         [0.0210, 0.0843, 0.0555, 0.2297, 0.0573, 0.0709, 0.2423, 0.2391]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1687, 0.8313, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2477, 0.0514, 0.7008, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4410, 0.0957, 0.3747, 0.0887, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0069, 0.0456, 0.0300, 0.7748, 0.1427, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0660, 0.0892, 0.0413, 0.6316, 0.1649, 0.0069, 0.0000, 0.0000],\n",
       "         [0.0396, 0.2288, 0.0090, 0.2000, 0.2061, 0.1949, 0.1217, 0.0000],\n",
       "         [0.3650, 0.0474, 0.0767, 0.0293, 0.3084, 0.0784, 0.0455, 0.0493]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4820, 0.5180, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1705, 0.4550, 0.3745, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0074, 0.7444, 0.0477, 0.2005, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.8359, 0.0416, 0.0525, 0.0580, 0.0119, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1195, 0.2061, 0.1019, 0.1153, 0.1814, 0.2758, 0.0000, 0.0000],\n",
       "         [0.0065, 0.0589, 0.0372, 0.3063, 0.1325, 0.3209, 0.1378, 0.0000],\n",
       "         [0.1416, 0.1519, 0.0384, 0.1643, 0.1207, 0.1254, 0.0169, 0.2408]],\n",
       "\n",
       "        [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.6369, 0.3631, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.2586, 0.7376, 0.0038, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.4692, 0.3440, 0.1237, 0.0631, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.1865, 0.4680, 0.0353, 0.1854, 0.1248, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0828, 0.7479, 0.0017, 0.0735, 0.0712, 0.0228, 0.0000, 0.0000],\n",
       "         [0.0522, 0.0517, 0.0961, 0.0375, 0.1024, 0.5730, 0.0872, 0.0000],\n",
       "         [0.0306, 0.2728, 0.0333, 0.1409, 0.1414, 0.0582, 0.0825, 0.2402]]],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "752e449c-ebde-4ca1-9835-d8876e89b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = torch.randn(B,T,head_size)\n",
    "q = torch.randn(B,T,head_size)\n",
    "wei = q @ k.transpose(-2, -1) * head_size**-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1ba080e0-a62b-4129-b000-86ae780aee93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0449)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "62352697-3c3b-451a-b7f1-2a087284cb92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0700)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "86c04eb3-dc41-4252-b390-b63dde296eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0918)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wei.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "e10a073f-afbc-4d6b-9534-e5f0fb95f76a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1925, 0.1426, 0.2351, 0.1426, 0.2872])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "99cc6554-4531-4213-a455-1d1302fa6c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0326, 0.0030, 0.1615, 0.0030, 0.8000])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(torch.tensor([0.1, -0.2, 0.3, -0.2, 0.5])*8, dim=-1) # gets too peaky, converges to one-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "45c2d305-9e08-4082-8d14-ec52d1fa4d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class LayerNorm1d: # implementing Layernorm\n",
    "\n",
    "  def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "    self.eps = eps\n",
    "    self.gamma = torch.ones(dim)\n",
    "    self.beta = torch.zeros(dim)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    # calculate the forward pass\n",
    "    xmean = x.mean(1, keepdim=True) #mean\n",
    "    xvar = x.var(1, keepdim=True) # batch variance\n",
    "    xhat = (x - xmean) / torch.sqrt(xvar + self.eps) # normalise to unit variance\n",
    "    self.out = self.gamma * xhat + self.beta\n",
    "    return self.out\n",
    "\n",
    "  def parameters(self):\n",
    "    return [self.gamma, self.beta]\n",
    "\n",
    "torch.manual_seed(1337)\n",
    "module = LayerNorm1d(100)\n",
    "x = torch.randn(32, 100) # batch size 32 of 100-dimensional vectors\n",
    "x = module(x)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c2b621fe-a00c-4a16-ba8c-d8a24150e1bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.1469), tensor(0.8803))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,0].mean(), x[:,0].std() # mean,std of one feature across all batch inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "6d01479f-18c4-4241-8946-463b3b31ccaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-9.5367e-09), tensor(1.0000))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,:].mean(), x[0,:].std() # mean,std of a single input from the batch, of its features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca694986-a817-4ca4-8c75-e6db65829db1",
   "metadata": {},
   "source": [
    "# FINAL CODE \n",
    "## [the code you are meant to run]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "6a12bbce-4432-4bba-84f1-beeea2efa83d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.21M parameters\n",
      "Step 0: Train loss 4.4973, Val loss 4.4888\n",
      "Step 100: Train loss 2.6073, Val loss 2.6630\n",
      "Step 200: Train loss 2.4463, Val loss 2.5023\n",
      "Step 300: Train loss 2.3445, Val loss 2.3964\n",
      "Step 400: Train loss 2.2577, Val loss 2.3099\n",
      "Step 500: Train loss 2.1838, Val loss 2.2463\n",
      "Step 600: Train loss 2.1262, Val loss 2.2024\n",
      "Step 700: Train loss 2.0722, Val loss 2.1367\n",
      "Step 800: Train loss 2.0028, Val loss 2.0807\n",
      "Step 900: Train loss 1.9794, Val loss 2.0561\n",
      "Step 1000: Train loss 1.9372, Val loss 2.0013\n",
      "Step 1100: Train loss 1.8832, Val loss 1.9698\n",
      "Step 1200: Train loss 1.8532, Val loss 1.9302\n",
      "Step 1300: Train loss 1.8295, Val loss 1.9204\n",
      "Step 1400: Train loss 1.8140, Val loss 1.8986\n",
      "Step 1500: Train loss 1.7878, Val loss 1.8772\n",
      "Step 1600: Train loss 1.7385, Val loss 1.8421\n",
      "Step 1700: Train loss 1.7317, Val loss 1.8360\n",
      "Step 1800: Train loss 1.7152, Val loss 1.8261\n",
      "Step 1900: Train loss 1.6907, Val loss 1.7994\n",
      "Step 2000: Train loss 1.6811, Val loss 1.7834\n",
      "Step 2100: Train loss 1.6706, Val loss 1.7798\n",
      "Step 2200: Train loss 1.6570, Val loss 1.7718\n",
      "Step 2300: Train loss 1.6302, Val loss 1.7575\n",
      "Step 2400: Train loss 1.6212, Val loss 1.7384\n",
      "Step 2500: Train loss 1.6138, Val loss 1.7301\n",
      "Step 2600: Train loss 1.5999, Val loss 1.7229\n",
      "Step 2700: Train loss 1.6058, Val loss 1.7298\n",
      "Step 2800: Train loss 1.5734, Val loss 1.7173\n",
      "Step 2900: Train loss 1.5693, Val loss 1.7124\n",
      "Step 3000: Train loss 1.5587, Val loss 1.7017\n",
      "Step 3100: Train loss 1.5562, Val loss 1.7145\n",
      "Step 3200: Train loss 1.5462, Val loss 1.7068\n",
      "Step 3300: Train loss 1.5268, Val loss 1.6725\n",
      "Step 3400: Train loss 1.5283, Val loss 1.6713\n",
      "Step 3500: Train loss 1.5229, Val loss 1.6621\n",
      "Step 3600: Train loss 1.5122, Val loss 1.6610\n",
      "Step 3700: Train loss 1.5140, Val loss 1.6562\n",
      "Step 3800: Train loss 1.4921, Val loss 1.6504\n",
      "Step 3900: Train loss 1.4935, Val loss 1.6550\n",
      "Step 4000: Train loss 1.4966, Val loss 1.6501\n",
      "Step 4100: Train loss 1.4884, Val loss 1.6484\n",
      "Step 4200: Train loss 1.4767, Val loss 1.6402\n",
      "Step 4300: Train loss 1.4841, Val loss 1.6314\n",
      "Step 4400: Train loss 1.4717, Val loss 1.6448\n",
      "Step 4500: Train loss 1.4615, Val loss 1.6028\n",
      "Step 4600: Train loss 1.4609, Val loss 1.6170\n",
      "Step 4700: Train loss 1.4494, Val loss 1.6113\n",
      "Step 4800: Train loss 1.4514, Val loss 1.6140\n",
      "Step 4900: Train loss 1.4499, Val loss 1.6104\n",
      "Step 4999: Train loss 1.4454, Val loss 1.6043\n",
      "\n",
      "surpnitated murms Ostries, int\n",
      "mighter way talk Hight-tir.\"\n",
      "\n",
      "\"I'm in a to gark get no, will MappeneTing the Grangains popeten.\n",
      "Neveily elaming the crear manne\n",
      "time much daint by greatly living and a fact trached with be was servalted by floor the Blailies.  Then adde at wearily waited.\n",
      "\n",
      "\"I wingerwar\n",
      "aror die many floor my astrienty wings they\n",
      "winger-by and the farm the king is prishaced the man slide to servery and must,\" answered humselve.\n",
      "\n",
      "\"Sir to your talk very?\" asked Dusp horries\n",
      "\n",
      "\n",
      " 36 yesou will that cast, you see will caired they\n",
      "all to crict stroubly,\" agreed the Wizard.\n",
      "\n",
      "\"Nonet,\" said their stairs thing, with a felt kick.\n",
      "\n",
      "\"telley,\" ssided will uneasily on ence, fellowing\n",
      "with cresion recopes with late breliasay talked by\n",
      "to lever near was strange\n",
      "wish little\n",
      "proce a round little cat head by very half man's of it.\n",
      "\n",
      "\"I, not awfully meliep through the\n",
      "nine named of the rilie of Voe, for you time,\" declared the man breatable of troud you wrry amazily all were hurt.\"\n",
      "\n",
      "\"Isnaped very very,\" said Dorothy?\" remaided; something alter.  \"I preside Mome.  Prieze the most secarely string to the\n",
      "Wizard the mountest.\n",
      "\n",
      "\"No!\" replied the rulie aroms we: the Wizard,\" he said Dorothy Eclared the chab-horse; \"but have much a cure\n",
      "mitte pretty.\"\n",
      "\n",
      "\"The menore by as\n",
      "she fear things!\" he sebested the piglet stelid gity-fell begind.\"\n",
      "\n",
      "\"For I beginxing being girl stragge.\"\n",
      "\n",
      "\"Why I'll not a by friend,\" said the like way Dorothy.  Then decented many stify prished, Jim, of our treathes that much gaic speessidies the\n",
      "corrarier little brid-sawayly that crepantfy the streathie mattie happered a man quick the chalumb-fam,\" said, \"\n",
      "remain we clustine, which he harm trotted the rectly in celimal?\"\n",
      "\n",
      "\n",
      "\"Well,\" sailime maste Jim are glabs,\" she willed the Gentles may pocket by eyes thing a givit, to cloused the each?\"\n",
      "\n",
      "\"On the Gargoylebt be a people trouble piglet Ozma!\" replied.  \"The other man, and my in the grush; I've the edger\n",
      "toustly down and this magless of the Giliglets.  Wwere\n",
      "are\n",
      "prop\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# Hyperparameters\n",
    "batch_size = 16\n",
    "block_size = 32\n",
    "max_iters = 5000\n",
    "eval_interval = 100\n",
    "learning_rate = 1e-3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "eval_iters = 200\n",
    "embedding_dim = 64\n",
    "num_heads = 4\n",
    "num_layers = 4\n",
    "dropout_rate = 0.0\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "# Load dataset\n",
    "with open('wiz_of_oz.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# Character mappings\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "stoi = {ch: i for i, ch in enumerate(chars)}\n",
    "itos = {i: ch for i, ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: ''.join([itos[i] for i in l])\n",
    "\n",
    "# Prepare train and validation splits\n",
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "train_size = int(0.9 * len(data))\n",
    "train_data = data[:train_size]\n",
    "val_data = data[train_size:]\n",
    "\n",
    "# Batch generation function\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    indices = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i + block_size] for i in indices])\n",
    "    y = torch.stack([data[i + 1:i + block_size + 1] for i in indices])\n",
    "    return x.to(device), y.to(device)\n",
    "\n",
    "# Estimate loss function\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    model.eval()\n",
    "    losses = {'train': torch.zeros(eval_iters), 'val': torch.zeros(eval_iters)}\n",
    "    for split in ['train', 'val']:\n",
    "        for i in range(eval_iters):\n",
    "            x, y = get_batch(split)\n",
    "            logits, loss = model(x, y)\n",
    "            losses[split][i] = loss.item()\n",
    "    model.train()\n",
    "    return {split: losses[split].mean() for split in losses}\n",
    "\n",
    "# Self-Attention Head\n",
    "class SelfAttentionHead(nn.Module):\n",
    "    def __init__(self, head_size):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(embedding_dim, head_size, bias=False)\n",
    "        self.query = nn.Linear(embedding_dim, head_size, bias=False)\n",
    "        self.value = nn.Linear(embedding_dim, head_size, bias=False)\n",
    "        self.tril = torch.tril(torch.ones(block_size, block_size)).to(device)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batch_size, time_steps, channels = x.shape\n",
    "        k = self.key(x)\n",
    "        q = self.query(x)\n",
    "        weights = (q @ k.transpose(-2, -1)) * (channels ** -0.5)\n",
    "        weights = weights.masked_fill(self.tril[:time_steps, :time_steps] == 0, float('-inf'))\n",
    "        weights = F.softmax(weights, dim=-1)\n",
    "        weights = self.dropout(weights)\n",
    "        v = self.value(x)\n",
    "        return weights @ v\n",
    "\n",
    "# Multi-Head Self-Attention\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(self, num_heads, head_size):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList([SelfAttentionHead(head_size) for _ in range(num_heads)])\n",
    "        self.proj = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = torch.cat([head(x) for head in self.heads], dim=-1)\n",
    "        return self.dropout(self.proj(out))\n",
    "\n",
    "# Feed-Forward Network\n",
    "class FeedForwardNetwork(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, 4 * embedding_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4 * embedding_dim, embedding_dim),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Transformer Block\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads):\n",
    "        super().__init__()\n",
    "        head_size = embedding_dim // num_heads\n",
    "        self.self_attention = MultiHeadSelfAttention(num_heads, head_size)\n",
    "        self.feed_forward = FeedForwardNetwork(embedding_dim)\n",
    "        self.layer_norm1 = nn.LayerNorm(embedding_dim)\n",
    "        self.layer_norm2 = nn.LayerNorm(embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.self_attention(self.layer_norm1(x))\n",
    "        x = x + self.feed_forward(self.layer_norm2(x))\n",
    "        return x\n",
    "\n",
    "# Bigram Language Model\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.position_embedding_table = nn.Embedding(block_size, embedding_dim)\n",
    "        self.transformer_blocks = nn.Sequential(*[TransformerBlock(embedding_dim, num_heads) for _ in range(num_layers)])\n",
    "        self.layer_norm = nn.LayerNorm(embedding_dim)\n",
    "        self.language_model_head = nn.Linear(embedding_dim, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets=None):\n",
    "        batch_size, time_steps = idx.shape\n",
    "        token_embeddings = self.token_embedding_table(idx)\n",
    "        position_embeddings = self.position_embedding_table(torch.arange(time_steps, device=device))\n",
    "        x = token_embeddings + position_embeddings\n",
    "        x = self.transformer_blocks(x)\n",
    "        x = self.layer_norm(x)\n",
    "        logits = self.language_model_head(x)\n",
    "\n",
    "        if targets is None:\n",
    "            return logits, None\n",
    "        else:\n",
    "            batch_size, time_steps, vocab_size = logits.shape\n",
    "            logits = logits.view(batch_size * time_steps, vocab_size)\n",
    "            targets = targets.view(batch_size * time_steps)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "            return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            idx_cond = idx[:, -block_size:]\n",
    "            logits, _ = self(idx_cond)\n",
    "            logits = logits[:, -1, :]\n",
    "            probs = F.softmax(logits, dim=-1)\n",
    "            idx_next = torch.multinomial(probs, num_samples=1)\n",
    "            idx = torch.cat((idx, idx_next), dim=1)\n",
    "        return idx\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "model = BigramLanguageModel().to(device)\n",
    "print(f'{sum(p.numel() for p in model.parameters()) / 1e6:.2f}M parameters')\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for iteration in range(max_iters):\n",
    "    if iteration % eval_interval == 0 or iteration == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"Step {iteration}: Train loss {losses['train']:.4f}, Val loss {losses['val']:.4f}\")\n",
    "\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "# Generate text\n",
    "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
    "generated_text = decode(model.generate(context, max_new_tokens=2000)[0].tolist())\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030c9164-a9f2-4433-80aa-a104e0db5a0a",
   "metadata": {},
   "source": [
    "## the text is gonna be nonsensical to read, don't worry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97722f8e-3760-43cc-a7db-95593038c75b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "'cuda-gpt-1'",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
